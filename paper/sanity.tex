\documentclass{bioinfo}
\usepackage{graphicx,amssymb}
\usepackage{authblk}
\usepackage{fullpage}
\usepackage{url}
\usepackage{rotating}
\usepackage{caption}
% \captionsetup[figure]{labelfont=bf}
% \captionsetup[table]{labelfont=bf,singlelinecheck=false}
%\usepackage[utf8]{inputenc}
\usepackage{lineno}
\newcommand{\junk}[1]{}
\copyrightyear{2015} \pubyear{2015}

\access{Advance Access Publication Date: Day Month Year}
\appnotes{Discovery Note}

\begin{document}\firstpage{1}

\subtitle{Sequence Analysis}

\title[Reproducibility]{On Genomic Repeats and Reproducibility}
\author[Firtina \textit{et~al}.]{Can Firtina\,$^{\text{\sfb 1,}}$ and Can Alkan\,$^{\text{\sfb 1},\ast}$}
\address{
$^{\text{\sf 1}}$Dept. of Computer Engineering, Bilkent University, 06800 Ankara, Turkey}

\corresp{$^\ast$To whom correspondence should be addressed.}

\history{Received on XXXXX; revised on XXXXX; accepted on XXXXX}

\editor{Associate Editor: XXXXXXX}

\abstract{
%\textbf{Motivation:} High throughput sequencing (HTS) technologies have been transforming biological research since their inception. More recent projects such as ClinSeq, now explore the possibility
%of using HTS in the clinic as medical tests. However, the reproducibility of HTS-based analysis is yet to be proven, especially within the complex regions of the genome.
%Although it is known that the HTS platforms do not yet produce perfect data, and every sequencing experiment may show different error profile, there is no study that characterize
%the effects of read mapping ambiguity within repeats and duplications.\\
\textbf{Results:} Here we present a comprehensive analysis on the reproducibility of computational characterization of genomic variants using HTS data. We re-analyzed the same data sets twice, using the same tools with the
same parameters, where we only altered the order of reads in the input (i.e. FASTQ file). Reshuffling caused the reads from repetitive regions being mapped to different locations in the second alignment,
and we observed similar results when we basically applied a scatter/gather mechanism for read mapping -- without prior shuffling.
Our results show that, some of the most common variation discovery algorithms
do not handle the ambiguous read mappings accurately when random locations are selected. In addition, we also observed that even when the exact same alignment is used, both GATK HaplotypeCaller and UnifiedGenotyper generate slightly different call sets, which we pinpoint to the variant filtration step. We conclude that, algorithms at each step of genomic variation
discovery and characterization need to treat ambiguous mappings and large training data sets in a deterministic fashion to ensure full replication of results.\\
\textbf{Availability:} Code, scripts, and the generated VCF files are available at \href{https://zenodo.org/record/65164/}{https://zenodo.org/record/65164/}\\
\textbf{Contact:} \href{calkan@cs.bilkent.edu.tr}{calkan@cs.bilkent.edu.tr}\\
\textbf{Supplementary information:} Supplementary data are available at \textit{Bioinformatics}
online.}

\maketitle
\linenumbers
\section{Introduction}

The advancements in high throughput sequencing (HTS) technologies have increased the demand on producing genome sequence data for many research questions, and prompted pilot projects to test its
power in clinical settings~\citep{Biesecker2009}. Any ``medical test'' to be reliably used in the clinic has to be proven to be both accurate and reproducible.
However, the fast-evolving nature of HTS technologies make it difficult to generate essentially same data using the same DNA resources. 

%It is not entirely surprising that 
We recently showed that 
resequencing the same DNA library 
with the same model HTS instrument 
twice 
and analyzing the data with the same algorithms 
may lead to different variation call sets~\citep{Kavak2015}. 
There may be multiple reasons for this effect,
such as degradation of DNA between two sequencing experiments, signal processing and base calling errors during sequencing, or different GC biases introduced while making sequencing libraries from the
same DNA~\citep{Kavak2015}. 

Aside from the potential problems in the ``wet lab'' side,
there may be additional complications in the ``dry lab'' analysis due to alignment errors and ambiguities due to genomic repeats.
Approximately half of the human genome consists of repeats, which cause ambiguity in read mapping when the read length is short. On the average, a 100 bp read generated by the Illumina platform may align to hundreds of genome locations with similar edit distance. 
The BWA-MEM~\citep{Li2009a,Li2013} mapper's  approach to handle such ambiguity is randomly selecting one location, and assigning the mapping quality to zero to inform the variant calling algorithms that the alignment may not be accurate. 

Although many algorithms were developed for HTS data analysis, a handful of computational pipelines from mapping to variant calling may be considered ``standard'' as they are commonly used in large-scale genome projects such as the 1000 Genomes Project~\citep{1000GP,1000GP2012,1000GP2015}. For example, to discover and genotype variants using Illumina data, first the reads are mapped to reference genome assembly using BWA-MEM~\citep{Li2009a,Li2013}, Bowtie~\citep{Langmead2009}, or a similar tool~\citep{Alkan2009,Weese2012} then the alignment files are processed using SAMtools~\citep{Li2009b} and Picard\footnote{\href{http://broadinstitute.github.io/picard/}{http://broadinstitute.github.io/picard/}}, and finally the single nucleotide variants (SNV) and indels are predicted and filtered using GATK~\citep{DePristo2011}, Platypus~\citep{Rimmer2014}, or Freebayes~\citep{Garrison2012}. 
Structural variation (SV) discovery is even more challenging as exemplified by the 1000 Genomes Project~\citep{1000GP,1000GP2012,Mills2011}, where more than 20 algorithms were used to characterize SVs.
Recently, the Genome in a Bottle Project~\citep{Zook2014} was started to set standards for accurate HTS data analysis for both research and clinical uses by addressing the differences in performances (i.e. accuracy, sensitivity, specificity, etc.) of different algorithms and different sequencing platforms
 to find a ``best practices'' approach.

In this study, we investigated whether some of the commonly used variant discovery algorithms
make use of this mapping quality information, and how they react to genomic repeats.
Briefly, 
we aligned two whole genome shotgun (WGS) data sets, one low (5X) and one high (44X) coverage genome
sequenced as part of the 1000 Genomes Project~\citep{1000GP2012} to the human reference genome (GRCh37) {\bf twice} using the same parameters. 
To test the effects of random placements,
we shuffled the order of reads in the second mapping experiment to make sure that the same random numbers are not used for the same reads. 
In a small scale test, we did not observe any differences
in the alignment files when we used non-random aligners such as Bowtie~\citep{Langmead2009}, and RazerS3~\citep{Weese2012}, and mrFAST~\citep{Alkan2009};
however, 
the map locations reported by BWA-MEM in repetitive regions differed among replications ($\sim$2.8\% of reads) as expected due to its random placement strategy.
We then generated two SNV and indel call sets each using GATK~\citep{DePristo2011} HaplotypeCaller, GATK UnifiedGenotyper, Freebayes~\citep{Garrison2012}, Platypus~\citep{Rimmer2014}, and SAMtools~\citep{Li2009b}, and structural variation (SV) call sets using DELLY~\citep{Rausch2012}, LUMPY~\citep{Layer2014}, and Genome STRiP~\citep{Handsaker2011,Handsaker2015} from each genome.

We observed substantial differences in the call sets generated by all of the variant discovery tools we tested. GATK's HaplotypeCaller showed a discrepancy of 0.4\% to 1.1\% , 
where UnifiedGenotyper showed the highest number of different calls between two alignments of the same data set (up to 12.76\%). 
Our results raise questions about reproducibility and accuracy of several commonly used genomic variation discovery tools.

\vspace*{-0.75cm}
\begin{methods}
\section{Methods}

\subsection*{Data acquisition}

We downloaded both whole genome and whole exome sequencing data sets from the 1000 Genomes Project~\citep{1000GP2012,1000GP2015} 
FTP server (\url{ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/}).

\vspace*{-0.3cm}
\subsection*{Read mapping, shuffling, and BAM file processing}
We used  Bowtie~\citep{Langmead2009}, RazerS3~\citep{Weese2012}, and BWA-MEM~\citep{Li2009a,Li2013}, and mrFAST~\citep{Alkan2009} 
(Table~\ref{tab:tools}) 
to align the reads generated by the Illumina 
platform to human reference genome (GRCh37) using default options. For testing the effects of read order, we randomly 
shuffled the reads in the FASTQ file using an in-house program, while keeping the relative order of read pairs intact.
The reason for reshuffling the reads is the following. In our small scale test, we noticed that BWA-MEM uses the same pseudorandom number generator seed in all mapping experiments. This
causes the same ambiguously mapping read to be randomly assigned to the same position when the read order is intact. However, when we shuffle the reads, the random number that corresponds to 
the read changes, causing it to be placed to another random location. Note that, the DNA molecules are hybridized randomly to the oligos on the flow cell, thus, our read randomization simulates the randomness
in cluster generation.
Next, we used SAMtools~\citep{Li2009b} to merge, sort, and index BAM files, and Picard$^1$ to remove PCR duplicates (MarkDuplicates).
We then followed the GATK's ``best practices'' guide~\citep{VanderAuwera2013} to
realign around indels (RealignerTargetCreator and IndelRealigner) and recalibrate base quality values (BaseRecalibrator). We used the 
resulting BAM files for SNV, indel, and SV calling. The names and version numbers of the tools we used are listed in Table~\ref{tab:tools}.

\vspace*{-0.3cm}
\subsection*{SNVs and indels}

We used GATK's~\citep{DePristo2011} both UnifiedGenotyper and HaplotypeCaller algorithms, SAMtools~\citep{Li2009b}, Freebayes~\citep{Garrison2012}, and Platypus~\citep{Rimmer2014} to characterize
SNV and indels. We followed the developers' recommendations and default parameters for all variant calling tools, including potential false positive filters. 
Specifically, we used both Variant Quality Score Recalibrator and SnpCluster algorithms to filter out false positives in GATK call sets, and additionally, 
we required a mapping quality of at least 30 for all tools we tested.
For GATK, we used the GATK Resource Bundle version 2.8 as the reference genome, reference genome annotations, and variant score recalibration training material.

\vspace*{-0.3cm}
\subsection*{Structural variation}

For structural variation discovery using the BWA-generated BAM files, we tested the reproducibility of the calls produced by DELLY~\citep{Rausch2012}, LUMPY~\citep{Layer2014}, and Genome STRiP~\citep{Handsaker2011,Handsaker2015}. 
We used default parameters for each tool and followed recommendations in relative documentations.
Additionally we also tested VariationHunter~\citep{Hormozdiari2009,Hormozdiari2010} (version 3.0), however, since VariationHunter explicitly requires mrFAST~\citep{Alkan2009,Xin2013} for read mapping, 
both the map location and the calls were fully reproduced. We therefore omit VariationHunter in comparisons in the remainder of the paper.

\vspace*{-0.3cm}
\subsection*{Variant annotation and comparison}

We downloaded the coordinates for segmental duplications, genes, coding exons, and common repeats from the UCSC Genome Browser~\citep{Kent2002}. 
We then used the BEDtools suite~\citep{Quinlan2010a} and standard UNIX tools 
 to calculate intersections between discrepancies in call sets with the annotations listed above.

\vspace*{-0.3cm}
\subsection*{Code and script availability} FASTQ read shuffling tool we developed, and all scripts we used to map reads and call variants
 are submitted to Zenodo archival site. In addition we also provide the VCF files generated for this study in the Zenodo site. The URL for this submission is \href{https://zenodo.org/record/65164/}{https://zenodo.org/record/65164/}, and the DOI is 10.5281/zenodo.32405.

%available at 
%\url{https://github.com/BilkentCompGen/reproducibility}.

\end{methods}

\section{Results}

%\subsection{Data and the tools}
\paragraph{Data and tools.}
We downloaded two whole genome shotgun sequence data sets, one at low coverage ($\sim$5X, HG00096) and one at high coverage ($\sim$ 44X, HG02107) from the 1000 Genomes Project~\citep{1000GP2012}.
We also downloaded 12 whole exome shotgun sequence data sets, again from the 1000 Genomes Project, with coverage ranging from 120X to 656X (Table~\ref{tab:data}). We tested the behavior of 
three different read mappers, four SNV/indel callers, and three SV characterization algorithms (Table~\ref{tab:tools}, Methods).

\begin{table*}[htb]
\caption{List of data sets used in this study.}
\begin{center}
\begin{tabular}{|l|r|r|r|r|}
\hline
{\bf Sample} & {\bf Type} & {\bf No. reads (mapped)} & {\bf Read length (bp)} & {\bf Coverage$^*$}\\
\hline
HG00096 & WGS & 146,347,388 & 100 & 4.88X\\
HG02107 & WGS & 1,319,393,745 & 101 & 44.42X\\
\hline
HG00250 & WES & 219,687,521 & 76 & 333.93X \\ 
HG00251 & WES & 115,030,162 & 90 & 207.05X \\ 
HG00330 & WES & 108,059,848 & 90 & 194.51X \\ 
HG00731 & WES & 327,901,475 & 76 & 498.41X \\ 
HG00732 & WES & 141,038,355 & 90 & 253.87X \\ 
HG01075 & WES & 431,625,989 & 76 & 656.07X \\ 
HG01083 & WES & 59,336,723 & 101 & 119.86X \\ 
HG01133 & WES & 61,187,487 & 101 & 123.60X \\ 
HG01136 & WES & 185,754,635 & 76 & 282.35X \\ 
HG01140 & WES & 97,205,053 & 90 & 174.97X \\ 
HG01167 & WES & 156,335,569 & 76 & 237.63X \\ 
HG01176 & WES & 63,122,492 & 101 & 127.51X \\ 
\hline
\end{tabular}
\end{center}
{\footnotesize We downloaded 2 whole genome (WGS) and 12 whole exome (WES) data sets from the 1000 Genomes Project~\citep{1000GP2012}. We
  used the WES data sets to test the SNV calls generated by GATK only.
  $^*$Coverage is calculated assuming the genome size as 3 Gbp for WGS data, and the exome size as 50 Mbp for WES data.}
%\line(1,0){450}
\label{tab:data}
\end{table*}

\begin{table*}[htb]
\caption{Tools and their version numbers we used in this study.}
\begin{center}
\begin{tabular}{|l|r|r|}
\hline
{\bf Tool} & {\bf Version} & {\bf Purpose}\\
\hline
Bowtie$^*$~\citep{Langmead2009} & 2.2.5 & Read Mapping \\
RazerS3$^*$~\citep{Weese2012} & 3.4 & Read Mapping\\
mrFAST$^*$~\citep{Alkan2009} & 2.6.1.0 & Read Mapping \\
BWA-MEM~\citep{Li2013} & 0.7.12-r1039 & Read Mapping\\
Picard$^1$ & 1.105 & BAM processing\\
SAMtools~~\citep{Li2009b} & 1.2 & SNVs and indels\\
GATK~\citep{DePristo2011} & 3.4-0-g7e26428 & SNVs and indels\\
Freebayes~\citep{Garrison2012} & v0.9.21-19-gc003c1e & SNVs and indels\\
Platypus~\citep{Rimmer2014} & 1.2.1 & SNVs and indels\\
DELLY~\citep{Rausch2012} & 0.6.7 & Structural Variation\\
LUMPY~\citep{Layer2014} & 0.2.11 & Structural Variation\\
Genome STRiP~\citep{Handsaker2011,Handsaker2015} & 2.00.1602 & Structural Variation\\
\hline
\end{tabular}
\end{center}
{\footnotesize $^*$In small-scale test only.}
%\line(1,0){450}
\label{tab:tools}
\end{table*}

\paragraph{Small scale test for ambiguous mapping.}
We first sub sampled 1 million reads from HG00096, and mapped it to the human reference genome (GRCh37) using Bowtie~\citep{Langmead2009}, RazerS3~\citep{Weese2012}, mrFAST~\citep{Alkan2009}, 
and BWA-MEM~\citep{Li2009a,Li2013}.
Next, we randomly shuffled the reads in the FASTQ file (Methods), and remapped the reordered reads to GRCh37 using the same tools. The read randomization essentially simulates the random nature of DNA hybridization on the flow cell.
After sorting the generated alignment files (i.e. SAM files), we confirmed that mrFAST and 
Bowtie generated the same alignments,
as described in 
their respective documentations, 
where BWA-MEM mapped some reads to different locations due to placing 
such reads to random locations (Supplementary Table~\ref{supptab:small-scale}).

\paragraph{Scatter/gather mapping.} Due to the large number of reads generated by HTS platforms, it is a common practice to use scatter/gather operations (or, its implementation using the MapReduce framework)
to distribute the work load to large number of CPUs in a cluster. This approach leverages the embarrassingly parallel nature of read mapping, where the FASTQ files that typically contain $>$50 million reads are
divided into ``chunks'' with just 1-2 million reads per file, the reads in each chunk are mapped separately, and the resulting BAM files are combined. Reasoning from our observation of 
different random placements of ambiguous reads when the reads are shuffled (Methods), we employed the scatter/gather method to map 1 million reads twice, using different chunk sizes. In this
experiment we divided the reads into chunks of 50,000 and 100,000 read pairs, mapped them using BWA-MEM, and observed mapping discordance ratios similar to that of random shuffling (2.1\%, Supplementary Table~\ref{supptab:bwa-map-scatter}).

\paragraph{WGS analysis}
We then repeated the same mapping, shuffling, and remapping strategy to the full versions of all data sets we downloaded, but we mapped using only BWA-MEM, since the other mappers 
would generate the same alignments before and after reshuffling based on the small scale test. We performed the standard BAM processing steps as described 
in~\citep{VanderAuwera2013} (Methods) to obtain sorted, duplicate-removed, realigned, recalibrated, and indexed BAM files. We also investigated BWA-MEM's behavior of random placements using the
HG00096 genome, and interestingly, although BWA-MEM reported zero mapping qualities for 
most of the discrepant read mappings ($\sim$97\%), it also assigned high MAPQ values ($\geq$30) for a fraction of them  ($\sim$0.75\%; Supplementary Table~\ref{supptab:bwa-map}). 

% main paper tables:

\begin{table*}[htb]
\caption{Summary of SNV and indel calls.}
\begin{center}
\begin{tabular}{|l|c|c||c|c||c|}
\hline
{\bf Tool} & \multicolumn{5}{c|}{\bf HG00096} \\
\hline
{\bf } & \multicolumn{2}{c||}{Original} & \multicolumn{2}{c||}{Shuffled} & {\it Diff (\%) }\\
\cline{2-6}
{\bf } & {\it All } & {\it Private } & {\it All } & {\it Private } & {\it } \\
\hline
HaplotypeCaller & 2,279,678 & 10,898 & 2,294,808 & 26,028 & 1.06 \\
UnifiedGenotyper & 2,470,690 & 315,174 & 2,174,342 & 18,826 & 13.41 \\
Freebayes & 2,400,545 & 992 & 2,400,595 & 1,042 & 0.08 \\
SAMtools & 2,277,691 & 2,683 & 2,277,674 & 2,666 & 0.24 \\
Platypus & 2,022,412 & 2,342 & 2,022,294 & 2,224 & 0.23 \\
\hline
\hline
{\bf } & \multicolumn{5}{c|}{\bf HG02107} \\
\hline
{\bf } & \multicolumn{2}{c||}{Original} & \multicolumn{2}{c||}{Shuffled} & {\it Diff (\%) }\\
\cline{2-6}
{\bf } & {\it All } & {\it Private } & {\it All } & {\it Private } & {\it } \\
\hline
HaplotypeCaller & 4,654,338 & 54,051 & 4,625,648 & 25,361 & 1.70 \\
UnifiedGenotyper & 4,717,918 & 38,635 & 4,723,109 & 272,491 & 6.53 \\
Freebayes & 5,174,644 & 4,715 & 5,189,285 & 19,356 & 0.46 \\
SAMtools & 5,355,604 & 9,838 & 5,355,053 & 9,287 & 0.36 \\
Platypus & 4,642,336 & 6,200 & 4,642,300 & 6,164 & 0.27 \\
\hline
\end{tabular}
\end{center}
{\footnotesize We list the number of SNV and indel calls in the genomes of HG00096 and HG02107 characterized by different tools using the reads in the original (i.e. as released by 1000 Genomes Project), and shuffled order.
Calls that are specific to one order of reads are listed as {\it Private}.
 The difference percentage is calculated as the total number of {\it Private} calls divided by the number of calls in the union set  (i.e. $\frac{|(O\setminus S)~\cup~ (S\setminus O)|}{|O\cup S|}$, $O$: original, $S$: shuffled). }
%\line(1,0){450}
\label{tab:snps-orig-vs-shuf}
\end{table*}


\begin{table*}[htb]
\caption{Summary of deletion calls.}
\begin{center}
\begin{tabular}{|l|c|c||c|c||c|}
\hline
{\bf Tool} & \multicolumn{5}{c|}{\bf HG00096} \\
\hline
{\bf } & \multicolumn{2}{c||}{Original} & \multicolumn{2}{c||}{Shuffled} & {\it Diff (\%) } \\
\cline{2-6}
{\bf } & {\it All } & {\it Private } & {\it All } & {\it Private } & {\it }\\
\hline
DELLY & 1,325 & 37 & 1,323 & 35 & 5.29 \\
Genome STRiP & 1,218 & 25 & 1,212 & 25 & 4.04 \\
\hline
\hline
{\bf } & \multicolumn{5}{c|}{\bf HG02107} \\
\hline
{\bf } & \multicolumn{2}{c||}{Original} & \multicolumn{2}{c||}{Shuffled} & {\it Diff (\%) } \\
\cline{2-6}
{\bf } & {\it All } & {\it Private } & {\it All } & {\it Private } & {\it }\\
\hline
DELLY & 13,517 & 831 & 13,505 & 819 & 11.51 \\
LUMPY$^*$ & 236 & 4 & 233 & 0 & 1.69 \\
Genome STRiP & 3,452 & 482 & 3,477 & 508 & 25.01 \\
\hline
\end{tabular}
\end{center}
{\footnotesize  We list the number of deletion calls in the genomes of HG00096 and HG02107 characterized by different tools using the reads in the original (i.e. as released by 1000 Genomes Project), and shuffled order.
  Calls that are specific to one order of reads are listed as {\it Private}. The difference percentage is calculated as the total number of {\it Private} calls divided by the number of calls in the union set  (i.e. $\frac{|(O\setminus S)~\cup~ (S\setminus O)|}{|O\cup S|}$, $O$: original, $S$: shuffled). $^*$ LUMPY crashed in the HG00096 genome analysis, and generated calls only from chromosome 3 in HG02107}
%\line(1,0){450}
\label{tab:dels-orig-vs-shuf}
\end{table*}

\paragraph{Single nucleotide variants and indels.}
We used GATK's HaplotypeCaller and UnifiedGenotyper~\citep{DePristo2011}, Freebayes~\citep{Garrison2012}, Platypus~\citep{Rimmer2014}, and SAMtools~\citep{Li2009b} to characterize
single nucleotide variants (SNVs) and indels within the HG00096 and HG02107 genomes using recommended parameters for each tool (Methods). We then compared each call set generated by the same tools using the reads in original vs. shuffled order using BEDtools~\citep{Quinlan2010a}, and found up to 13.41\% of variants to be called in one alignment of the same data but not in the other (Table~\ref{tab:snps-orig-vs-shuf}).
Next, we investigated the underlying sequence context of the SNVs 
and indels differently detected using the same tools with two different alignments (i.e. original vs shuffled order). 
As expected, 72- to 80\% of the discrepant calls were found within common repeats and segmental duplications (Supplementary Tables~\ref{supptab:orig-vs-shuf-hc},\ref{supptab:orig-vs-shuf-ug},\ref{supptab:orig-vs-shuf-freebayes},\ref{supptab:orig-vs-shuf-samtools},\ref{supptab:orig-vs-shuf-platypus}). 
In most genomic analysis studies high copy regions are removed from consideration, however, we also observed 565 to 6,099 
SNVs that were called within one alignment but not the other that map to coding exons using UnifiedGenotyper (Supplementary Table~\ref{supptab:orig-vs-shuf-ug}). 
Furthermore, 2,910 of the 6,099 (47.71\%) discordant exonic SNVs predicted by GATK UnifiedGenotyper did not intersect with any common repeats or segmental duplications.
Freebayes, Platypus, and SAMtools predictions were more reproducible, as $>$98.5\% of the calls were identical, and the number of exonic discrepant SNV calls were substantially lower than
that of GATK's (Supplementary Tables~\ref{supptab:orig-vs-shuf-freebayes},\ref{supptab:orig-vs-shuf-samtools},\ref{supptab:orig-vs-shuf-platypus}). 

\paragraph{Structural variation.}
Next, we analyzed the deletion calls predicted using DELLY, LUMPY, and Genome STRiP. Unfortunately, LUMPY crashed while running on the HG00096 genome, and we were able to obtain calls only from chromosome 3 using the HG02107 data. Nevertheless, all three SV detection tools we tested showed 3.5\%- to 25.01\% difference in call sets using the original vs. shuffled order read data sets (Table~\ref{tab:dels-orig-vs-shuf}). As for the SNV and indels, the discrepancies were mostly found within repeats and duplications, however, only a couple of deletion calls intersected with coding exons (Supplementary Tables~\ref{supptab:orig-vs-shuf-delly-deletions},~\ref{supptab:orig-vs-shuf-svtoolkit},~\ref{supptab:orig-vs-shuf-lumpy}). 

We also used DELLY to predict inversions, tandem duplications, and translocations and obtained different calls in original vs shuffled order read data: $\sim$3\% of deletion, $\sim$4\% of tandem duplication, $\sim$6\% of inversion, and $\sim$3.6\% of translocation calls were specific to a single alignment, and $>$91\% of these differences intersected with common repeats. Owing to the difficulties in predicting
these types of SVs, more discrepant calls intersected with functionally important regions (i.e. genes and coding exons; Supplementary Tables~\ref{supptab:orig-vs-shuf-delly-dups},\ref{supptab:orig-vs-shuf-delly-inv},\ref{supptab:orig-vs-shuf-delly-trans}).

\paragraph{Reusing the same alignments.}
More interestingly, when we ran GATK's both HaplotypeCaller and UnifiedGenotyper on the {\bf same} BAM file twice, we observed discrepant calls similar to using two different BAM files generated from original vs. shuffled read order. HaplotypeCaller generated more consistent calls when compared to UnifiedGenotyper, which produced up to 4,650 discordant exonic SNVs (Supplementary Tables~\ref{supptab:orig-vs-orig2-hc},\ref{supptab:orig-vs-orig2-ug}). Other tools produced no discrepancies (Supplementary Tables~\ref{supptab:orig-vs-orig2-freebayes}-\ref{supptab:orig-vs-orig2-lumpy}).
Detailed analysis of these discordancies revealed that  21,497 of the 21,510 ($>$99.9\%) ``second-run specific'' HaplotypeCaller calls were initially found in the first run, however filtered in the Variant Quality Score Recalibration (VQSR) step. Similarly, 10,631 of the 10,646 ``first-run specific'' HaplotypeCaller calls were eliminated by VQSR in the second run. We then performed a line-by-line analysis in such calls, and found that the {\it VQSLOD} score was calculated differently, although the training data was the same in both runs. We then confirmed our observation by rerunning the VQSR filter on 
one of the VCF files five times. Each iteration of the VQSR filtering generated a different set of VQSLOD values, causing different variants to be filtered.

\paragraph{Replication in exome analysis.}
Finally, we tested the effect of discordant call sets generated by GATK even with the same alignment files using 12 whole exome shotgun sequence (WES) data sets from the 1000 Genomes Project (Table~\ref{tab:data}). We followed the same alignment and post-processing procedures for the WES data sets using BWA-MEM, SAMtools, Picard, and GATK's IndelRealigner and BaseRecalibrator. We then generated two call sets using HaplotypeCaller, and two call sets using UnifiedGenotyper on the same BAM files, followed with filtering as described in the GATK Best Practices Guide~\citep{VanderAuwera2013} (Methods). In this experiment, we used the multi-sample calling options (i.e. SNV and indels in all samples were called simultaneously). Both HaplotypeCaller and UnifiedGenotyper produced discordant calls at 1-to 3\% rate
(Supplementary Tables~\ref{supptab:orig-vs-orig2-hc},\ref{supptab:orig-vs-orig2-ug},\ref{supptab:orig-vs-orig2-multiple-hc},\ref{supptab:orig-vs-orig2-multiple-ug}). 


\vspace*{-0.5cm}
\section{Discussion and Recommendations}

\junk{
The introduction of HTS platforms  quickly revolutionized the way we do biological research\citep{Mardis2008,Metzker2010}. Furthermore, HTS technology  already started to make impact on human health in the form of personalized medicine
through clinical sequencing~\citep{Biesecker2009}, breast cancer subtype detection~\citep{Bosdet2013}, and small molecule drug target site identification~\citep{Rodriguez2014}. However, both sequencing technologies themselves~\citep{Kavak2015},
 and the computational tools are still far from being mature in terms of accuracy~\citep{Alkan2011,Nielsen2011}. The complexity and repetitive nature of human genomes introduce further challenges for reliable characterization of genomic variants~\citep{Treangen2012}.
}

In this paper, we documented the effects of different approaches to handle ambiguities in read mapping due to genomic repeats. We focused on more widely used computational tools for read mapping and variant calling. Our main observation was that, random placement of ambiguously mapping reads have an effect on variation calling. Although discordancies within repeats are less of a concern due to their relatively negligible 
effects to phenotype, we also discovered hundreds to thousands variants differently detected within coding exons. GATK UnifiedGenotyper showed the most discrepancies, where the discordant calls were less pronounced in Freebayes and Platypus results. It was also surprising to see differences in call sets generated using HaplotypeCaller and UnifiedGenotyper even when the same alignments and variant filtration training data sets were provided. Although we could not fully characterize the reasons
of this observation with GATK, since HaplotypeCaller algorithm is yet unpublished, and UnifiedGenotyper algorithm description~\citep{DePristo2011} is presented as a summary, we observed that the differences were
mainly due to different calculation of the {\it VQSLOD} score during the Variant Quality Score Recalibration (VQSR) filter. The VQSR algorithm is an expectation-maximization based algorithm~\citep{DePristo2011},
which uses ``true sites'' (i.e. HapMap 3 sites, Omni 2.5 SNP chip array, etc.) as training data sets. Since we also used the same training data sets, 
we speculate that the differences in VQSLOD calculations is due to the random sampling of the training data
to reduce computational burden\footnote{This random subsampling can be seen in the GATK code VariantDataManager.java at \url{https://github.com/broadgsa/gatk-protected/blob/master/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/variantrecalibration/} (commit ID: {\tt 8ea4dcab8d78e7a7d573fcdc519bd0947a875c06}, line 255)}. 

\paragraph{Recommendations.}
 Full reproducibility could only be achieved through using deterministic methods. Therefore we recommend to opt for a deterministic read mapper such as Bowtie, mrFAST, etc., and a deterministic
variant caller, such as Platypus or Freebayes.
 It may be possible to work around the GATK's VQSLOD calculation problem outlined above by setting the {\tt maxNumTrainingData} parameter and other downsampling parameters to high values, however, we recommend disabling these randomizations by default to be a better practice for uninformed users. In our test, changing only the {\tt maxNumTrainingData} parameter did not fully resolve the variant filtration problem, which points that there may be other downsampling and/or randomization step within the VQSR calculation.


\paragraph{Conclusion.}
Mapping short reads to repetitive regions accurately still remains an open problem~\citep{Treangen2012}. Bowtie and mrFAST use 
edit distance and paired-end span distance 
to deterministically assign a single ``best'' map location to ambiguously mapping reads, where BWA-MEM selects a random map location all mapping properties are calculated the same. BWA-MEM assigns a zero mapping quality
to such randomly selected alignments. This approach is still perfectly valid since it informs the downstream analysis tools for problematic alignments, however, as we have documented in this manuscript, 
several variant discovery tools do not fully utilize this information. Complete analysis of the reasons for these discrepancies may warrant code inspection and full disclosure of every algorithmic detail.

The differences in call sets we observed in this study 
may have similar sensitivity and specificity.
It is also expected to
have differences between different algorithms and/or parameters, but
obtaining different results should not be due to the order of {\it independently generated} reads in the input file. 
We may simply count these discordant variants towards  false positives and negatives, however, 
we argue that computational predictions should not be effected by luck, and inaccuracies in computational results should be deterministic.
No genomic variant characterization algorithm achieves 100\% accuracy yet, even with perfect simulation data, but it is only possible to analyze and understand the shortcomings of 
deterministic algorithms, and impossible to fully understand how an algorithm performs if it makes random choices.
When it comes to use any technology for human health, one would prefer full reproducibility. 

\vspace*{-0.5cm}

\section*{Acknowledgments}

We thank H.I. Ozercan, A. Gundogdu, A.K. Senol, and M.Y. Ozkaya for the initial observation of the effects of reshuffling reads in alignment results using BWA-MEM. We also thank M. Somel, 
O. Gokcumen, E. Cicek, and O. Tastan for
their valuable comments during the preparation of this manuscript.

\paragraph{Funding.}
Funding for this project was provided by a Marie Curie Career Integration Grant (303772) and an 
EMBO Installation Grant (IG-2521) to C.A.

\vspace*{-0.5cm}

\small
\bibliographystyle{natbib}

\bibliography{calkan.bib}

\clearpage

\input{supptables.tex}

\end{document}
