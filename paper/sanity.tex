\documentclass{bioinfo}
\usepackage{graphicx,amssymb}
\usepackage{authblk}
\usepackage{fullpage}
\usepackage{url}
\usepackage{rotating}
\usepackage{caption}
\usepackage{multirow}
% \captionsetup[figure]{labelfont=bf}
% \captionsetup[table]{labelfont=bf,singlelinecheck=false}
%\usepackage[utf8]{inputenc}
\usepackage{lineno}
\newcommand{\junk}[1]{}
\copyrightyear{2015} \pubyear{2015}

\access{Advance Access Publication Date: Day Month Year}
\appnotes{Discovery Note}
\setlength{\textfloatsep}{0.2cm}


\begin{document}\firstpage{1}

\subtitle{Sequence Analysis}

\title[Reproducibility]{On Genomic Repeats and Reproducibility}
\author[Firtina \textit{et~al}.]{Can Firtina\,$^{\text{\sfb 1}}$ and Can Alkan\,$^{\text{\sfb 1},\ast}$}
\address{
$^{\text{\sf 1}}$Dept. of Computer Engineering, Bilkent University, 06800 Ankara, Turkey}

\corresp{$^\ast$To whom correspondence should be addressed.}
\history{Received on XXXXX; revised on XXXXX; accepted on XXXXX}

\editor{Associate Editor: XXXXXXX}

\abstract{
%\textbf{Motivation:} High throughput sequencing (HTS) technologies have been transforming biological research since their inception. More recent projects such as ClinSeq, now explore the possibility
%of using HTS in the clinic as medical tests. However, the reproducibility of HTS-based analysis is yet to be proven, especially within the complex regions of the genome.
%Although it is known that the HTS platforms do not yet produce perfect data, and every sequencing experiment may show different error profile, there is no study that characterize
%the effects of read mapping ambiguity within repeats and duplications.\\
\textbf{Results:} Here we present a comprehensive analysis on the reproducibility of computational characterization of genomic variants using HTS data. We re-analyzed the same data sets twice, using the same tools with the
same parameters, where we only altered the order of reads in the input (i.e. FASTQ file). Reshuffling caused the reads from repetitive regions being mapped to different locations in the second alignment,
and we observed similar results when we only applied a scatter/gather approach for read mapping -- without prior shuffling.
Our results show that, some of the most common variation discovery algorithms
do not handle the ambiguous read mappings accurately when random locations are selected. In addition, we also observed that even when the exact same alignment is used, the GATK HaplotypeCaller generates slightly different call sets, which we pinpoint to the variant filtration step. We conclude that, algorithms at each step of genomic variation
discovery and characterization need to treat ambiguous mappings in a deterministic fashion to ensure full replication of results.\\
\textbf{Availability:} Code, scripts, and the generated VCF files are available at DOI:10.5281/zenodo.32611\\ 
\textbf{Contact:} \href{calkan@cs.bilkent.edu.tr}{calkan@cs.bilkent.edu.tr}\\
\textbf{Supplementary information:} Supplementary data are available at \textit{Bioinformatics}
online.}

\maketitle
\linenumbers
\section{Introduction}

The advancements in high throughput sequencing (HTS) technologies have increased the demand on producing genome sequence data for many research questions, and prompted pilot projects to test its
power in clinical settings~\citep{Biesecker2009}. Any ``medical test'' to be reliably used in the clinic has to be proven to be both accurate and reproducible.
However, the fast-evolving nature of HTS technologies make it difficult to achieve full reproducibility. %to generate essentially same data using the same DNA resources. 

%It is not entirely surprising that 
We recently showed that 
resequencing the same DNA library 
with the same model HTS instrument 
twice 
and analyzing the data with the same algorithms 
may lead to different variation call sets~\citep{Kavak2015}. 
\junk{
There may be multiple reasons for this effect,
such as degradation of DNA between two sequencing experiments, signal processing and base calling errors during sequencing, or different GC biases introduced while making sequencing libraries from the
same DNA~\citep{Kavak2015}. 
}
Aside from the potential problems in the ``wet lab'' side,
there may be additional complications in the ``dry lab'' analysis due to alignment errors and ambiguities due to genomic repeats.
The repetitive nature of the  human genome causes ambiguity in read mapping when the read length is short~\citep{Treangen2012}. On the average, a 100 bp read generated by the Illumina platform may align to hundreds of genome locations with similar edit distance. 
The BWA-MEM~\citep{Li2013} mapper's  approach to handle such ambiguity is randomly selecting one location, and assigning the mapping quality to zero to inform the variant calling algorithms that the alignment may not be accurate. 

Although many algorithms were developed for HTS data analysis, a handful of computational pipelines from mapping to variant calling may be considered ``standard'' as they are commonly used in large-scale genome projects such as the 1000 Genomes Project~\citep{1000GP2015}. 
\junk {For example, to discover and genotype variants using Illumina data, first the reads are mapped to reference genome assembly using BWA-MEM~\citep{Li2013}, Bowtie~\citep{Langmead2009}, or a similar tool~\citep{Alkan2009,Weese2012} then the alignment files are processed using SAMtools~\citep{Li2009b} and Picard\footnote{\href{http://broadinstitute.github.io/picard/}{http://broadinstitute.github.io/picard/}}, and finally the single nucleotide variants (SNV) and indels are predicted and filtered using GATK~\citep{DePristo2011}, Platypus~\citep{Rimmer2014}, or Freebayes~\citep{Garrison2012}. 
Structural variation (SV) discovery is even more challenging as exemplified by the 1000 Genomes Project~\citep{1000GP2015,Mills2011}, where more than 20 algorithms were used to characterize SVs.
} 
Recently, the Genome in a Bottle Project~\citep{Zook2014} was started to set standards for accurate HTS data analysis for both research and clinical uses by addressing the differences in detection performances 
of different algorithms and different sequencing platforms.
% to find a ``best practices'' approach.

In this study, we investigated whether some of the commonly used variant discovery algorithms
make use of this mapping quality information, and how they react to genomic repeats.
Briefly, 
we aligned two whole genome shotgun (WGS) data sets, one low and one high coverage genome
sequenced as part of the 1000 Genomes Project~\citep{1000GP2015} to the human reference genome (GRCh37) {\bf twice} using the same parameters. 
In the second mapping 
we shuffled the order of reads  to make sure that the same random numbers are not used for the same reads. 
\junk{ In a small scale test, we did not observe any differences
in the alignment files when we used deterministic aligners such as Bowtie~\citep{Langmead2009} and mrFAST~\citep{Alkan2009};
however, 
the map locations reported by BWA-MEM in repetitive regions differed among replications ($\sim$2.1\% of reads) as expected due to its random placement strategy.}
We then generated two SNV and indel call sets each from each genome.

We observed substantial differences in the call sets generated by all of the variant discovery tools we tested except VariationHunter/ CommonLAW. However, VariationHunter explicitly requires
 a deterministic read mapper, therefore we removed it from further comparisons. GATK's HaplotypeCaller showed discordancies of 1.06\% to 1.7\% in SNV/indel call sets,
 where Freebayes showed the most concordancy (up to 99.2\%). Genome STRiP showed the greatest discrepancy in structural variation calls (up to 25\%).
Our results raise questions about reproducibility of callsets generated with several commonly used genomic variation discovery tools.

\vspace*{-0.75cm}
\begin{methods}
\section{Methods}

\subsection*{Data acquisition}

We downloaded both whole genome and whole exome sequencing data sets from the 1000 Genomes Project~\citep{1000GP2015} 
FTP server.% (\url{ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/}).

\vspace*{-0.3cm}
\subsection*{Read mapping, shuffling, and BAM file processing}
We used  Bowtie~\citep{Langmead2009}, RazerS3~\citep{Weese2012}, and BWA-MEM~\citep{Li2013}, and mrFAST~\citep{Alkan2009} 
(Table~\ref{supptab:tools}) 
to align the reads generated by the Illumina 
platform to human reference genome (GRCh37) using default options. For testing the effects of read order, we randomly 
shuffled the reads in the FASTQ file using an in-house program, while keeping the relative order of read pairs intact.
The reason for reshuffling the reads is the following. In our small scale test, we noticed that BWA-MEM uses the same pseudorandom number generator seed in all mapping experiments. This
causes the same ambiguously mapping read to be randomly assigned to the same position when the read order is intact. However, when we shuffle the reads, the random number that corresponds to 
the read changes, causing it to be placed to another random location. Note that, the DNA molecules are hybridized randomly to the oligos on the flow cell, thus, our read randomization simulates the randomness
in cluster generation.
Next, we used SAMtools~\citep{Li2009b} to merge, sort, and index BAM files, and Picard$^1$ to remove PCR duplicates (MarkDuplicates).
We then followed the GATK's ``best practices'' guide~\citep{VanderAuwera2013} to
realign around indels (RealignerTargetCreator and IndelRealigner) and recalibrate base quality values (BaseRecalibrator). We used the 
resulting BAM files for SNV, indel, and SV calling. The names and version numbers of the tools we used are listed in  Table~\ref{supptab:tools}.

\vspace*{-0.3cm}
\subsection*{SNVs and indels}

We used GATK's~\citep{DePristo2011} HaplotypeCaller algorithm, SAMtools~\citep{Li2009b}, Freebayes~\citep{Garrison2012}, and Platypus~\citep{Rimmer2014} to characterize
SNV and indels. We followed the developers' recommendations and default parameters for all variant calling tools, including potential false positive filters. 
Specifically, we used both Variant Quality Score Recalibrator and SnpCluster methods to filter out false positives in GATK call sets, and for other tools
we required a variant quality of at least 30.
For GATK, we used the GATK Resource Bundle version 2.8 as the reference genome and its annotations, and variant score recalibration training material.

\vspace*{-0.3cm}
\subsection*{Structural variation}

For structural variation discovery using the BWA-generated BAM files, we tested the reproducibility of the calls produced by DELLY~\citep{Rausch2012}, LUMPY~\citep{Layer2014}, Genome STRiP~\citep{Handsaker2015}, and VariationHunter/ CommonLAW~\citep{Hormozdiari2009,Hormozdiari2011b}. We note that VariationHunter explicitly remaps reads to the reference genome using mrFAST, which is a deterministic mapper, therefore we removed it from further comparisons.
We used default parameters for each tool and followed recommendations in relative documentations.

\vspace*{-0.3cm}
\subsection*{Variant annotation and comparison}

We downloaded the coordinates for segmental duplications, genes, coding exons, and common repeats from the UCSC Genome Browser~\citep{Kent2002}. 
We then used the BEDtools suite~\citep{Quinlan2010a} and standard UNIX tools 
 to calculate the discrepancies among the call sets and their underlying sequence annotations.

\vspace*{-0.3cm}
\subsection*{Code and script availability} FASTQ read shuffling tool we developed, all scripts we used to map reads and call variants,
and the VCF files generated for this study are available at the Zenodo site. The DOI for this submission is 10.5281/zenodo.32611.
% are submitted to Zenodo archival site. In addition we also provide 

%available at 
%\url{https://github.com/BilkentCompGen/reproducibility}.

\end{methods}

\section{Results}

%\subsection{Data and the tools}
\paragraph{Data and tools.}
We downloaded two WGS data sets, one at low coverage ($\sim$5X, HG00096) and one at high coverage ($\sim$ 44X, HG02107), and 12 WES data sets with coverage ranging from 120X to 656X from the 1000 Genomes Project~\citep{1000GP2015}
%We also downloaded 12 whole exome shotgun sequence data sets, again from the %1000 Genomes Project, with coverage ranging from 120X to 656X 
(Table~\ref{supptab:data}). We tested the behaviors of 
three different read mappers, four SNV/indel callers, and three SV characterization algorithms (Table~\ref{supptab:tools}, Methods).

\paragraph{Small scale test for ambiguous mapping.}
We first sub sampled 1 million reads from HG00096, and mapped it to the human reference genome (GRCh37) using Bowtie, RazerS3, mrFAST, 
and BWA-MEM~\citep{Li2013}.
Next, we randomly shuffled the reads in the FASTQ file (Methods), and remapped the reordered reads to GRCh37 using the same tools. The read randomization simulates the random nature of DNA hybridization on the flow cell.
%After sorting the generated alignment files (i.e. SAM files), 
We confirmed that mrFAST and 
Bowtie generated the same alignments,
as described in 
their respective documentations, 
where BWA-MEM mapped several reads to different locations due to placing 
such reads to random locations (Table~\ref{supptab:small-scale}).

\paragraph{Read mapping in parallel.} Due to the large number of reads generated by HTS platforms, it is a common practice to use scatter/gather operations (or, its implementation using the MapReduce framework)
to distribute the work load to large number of CPUs in a cluster. This approach leverages the embarrassingly parallel nature of read mapping, where the FASTQ files that typically contain $>$50 million reads are
divided into ``chunks'' with just 1-2 million reads per file, the reads in each chunk are mapped separately, and the resulting BAM files are combined. Reasoning from our observation of 
different random placements of ambiguous reads when the reads are shuffled, we employed the scatter/gather method to map 1 million reads twice, using different chunk sizes. In this
experiment we divided the reads into chunks of 50,000 and 100,000 read pairs, mapped them using BWA-MEM, and observed mapping discordance ratios similar to that of random shuffling (2.1\%,  Table~\ref{supptab:bwa-map-scatter}). We also observed less pronounced differences in read mapping when different number of threads are used for the same FASTQ file (0.05\%,  Table~\ref{supptab:threadmap}).

\paragraph{WGS analysis.}
We then repeated the same mapping strategy to the full versions of all data sets we downloaded, but we mapped using only BWA-MEM, since we observed the other mappers to be deterministic
 based on the small scale test.  We also investigated BWA-MEM's behavior of random placements using the
HG00096 genome, and interestingly, although BWA-MEM reported zero mapping qualities for 
most of the discrepant read mappings ($\sim$97\%), it also assigned high MAPQ values ($\geq$30) for a fraction of them  ($\sim$0.75\%;  Table~\ref{supptab:bwa-map}). 


\paragraph{Single nucleotide variants and indels.}
% UPDATED
We used GATK's HaplotypeCaller, Freebayes, Platypus, and SAMtools to characterize
SNVs and indels within the HG00096 and HG02107 genomes using recommended parameters for each tool (Methods). 
We did not evaluate GATK UnifiedGenotyper since it is deprecated by its developers.
% END_UPDATED
We then compared each call set generated by the same tools using the reads in original vs. shuffled order using BEDtools~\citep{Quinlan2010a}, and found up to 1.70\% of variants to be called in one alignment of the same data but not in the other (Table~\ref{tab:vars-orig-vs-shuf}).
Next, we investigated the underlying sequence context of the SNVs 
and indels differently detected using the same tools with two different alignments (i.e. original vs shuffled order). 
As expected, 72- to 80\% of the discrepant calls were found within common repeats and segmental duplications (Tables~\ref{supptab:orig-vs-shuf-hc},\ref{supptab:orig-vs-shuf-freebayes},\ref{supptab:orig-vs-shuf-samtools},\ref{supptab:orig-vs-shuf-platypus}). 
In most genomic analysis studies high copy regions are removed from consideration, however, we also observed 253 to 1,249 
SNVs that were called within one alignment but not the other that map to coding exons using HaplotypeCaller (Table~\ref{supptab:orig-vs-shuf-hc}). 
% UPDATED
Furthermore, 1,543 of the 1,884 (81.9\%) discordant exonic SNVs predicted by GATK HaplotypeCaller (either original or shuffled order) {\bf did not} intersect with any common repeats or segmental duplications.
% 1000 of 1241 for orig hg02107 hc
%(05:12:42 PM) Can Fırtına: 543 of 643 for shuf
%(05:13:02 PM) Can Fırtına: in total 1543 of 1884
% END_UPDATED
Freebayes, Platypus, and SAMtools predictions were more reproducible, as $>$98.5\% of the calls were identical, and the number of exonic discrepant SNV calls were substantially lower than
that of GATK's (Tables~\ref{supptab:orig-vs-shuf-freebayes},\ref{supptab:orig-vs-shuf-samtools},\ref{supptab:orig-vs-shuf-platypus}). 

\begin{table}[htb]
  \caption{Summary of SNV, small indel, and deletion calls.}
\begin{center}
\begin{tabular}{|l|c|c||c|c||c|}
\hline
{\bf Tool} & \multicolumn{5}{c|}{\bf HG00096} \\
\hline
{\bf } & \multicolumn{2}{c||}{Original} & \multicolumn{2}{c||}{Shuffled} & {\it Diff (\%) }\\
\cline{2-6}
{\bf } & {\it All } & {\it Private } & {\it All } & {\it Private } & {\it } \\
\hline
HaplotypeCaller & 2,279,678 & 10,898 & 2,294,808 & 26,028 & 1.06 \\
Freebayes & 2,400,545 & 992 & 2,400,595 & 1,042 & 0.08 \\
SAMtools & 2,277,691 & 2,683 & 2,277,674 & 2,666 & 0.24 \\
Platypus & 2,022,412 & 2,342 & 2,022,294 & 2,224 & 0.23 \\
DELLY & 1,325 & 37 & 1,323 & 35 & 5.29 \\
Genome STRiP & 1,218 & 25 & 1,212 & 25 & 4.04 \\
%VariationHunter$^\ast$ & 128 & 0 & 128 & 0 & 0 \\
\hline
\hline
{\bf } & \multicolumn{5}{c|}{\bf HG02107} \\
\hline
{\bf } & \multicolumn{2}{c||}{Original} & \multicolumn{2}{c||}{Shuffled} & {\it Diff (\%) }\\
\cline{2-6}
{\bf } & {\it All } & {\it Private } & {\it All } & {\it Private } & {\it } \\
\hline
HaplotypeCaller & 4,654,338 & 54,051 & 4,625,648 & 25,361 & 1.70 \\
Freebayes & 5,174,644 & 4,715 & 5,189,285 & 19,356 & 0.46 \\
SAMtools & 5,355,604 & 9,838 & 5,355,053 & 9,287 & 0.36 \\
Platypus & 4,642,336 & 6,200 & 4,642,300 & 6,164 & 0.27 \\
DELLY & 13,517 & 831 & 13,505 & 819 & 11.51 \\
LUMPY$^*$ & 236 & 4 & 233 & 0 & 1.69 \\
Genome STRiP & 3,452 & 482 & 3,477 & 508 & 25.01 \\
%VariationHunter$^\ast$ & 1,044 & 0 & 1,044 & 0 & 0 \\
\hline
%\end{tabular}
%\end{center}
%{\footnotesize We list the number of SNV and indel calls in the genomes of HG00096 and HG02107 characterized by different tools using the reads in the original (i.e. as released by 1000 Genomes Project), and %shuffled order.
%Calls that are specific to one order of reads are listed as {\it Private}.
% The difference percentage is calculated as the total number of {\it Private} calls divided by the number of calls in the union set  (i.e. $\frac{|(O\setminus S)~\cup~ (S\setminus O)|}{|O\cup S|}$, $O$: %original, $S$: shuffled). }
%\line(1,0){450}
%\label{tab:snps-orig-vs-shuf}
%\end{table}
%\begin{table}[htb]
%\caption{Summary of deletion calls.}
%\begin{center}
%\begin{tabular}{|l|c|c||c|c||c|}
%\hline
%{\bf Tool} & \multicolumn{5}{c|}{\bf HG00096} \\
%\hline
%{\bf } & \multicolumn{2}{c||}{Original} & \multicolumn{2}{c||}{Shuffled} & {\it Diff (\%) } \\
%\cline{2-6}
%{\bf } & {\it All } & {\it Private } & {\it All } & {\it Private } & {\it }\\
%\hline
%\hline
%\hline
%{\bf } & \multicolumn{5}{c|}{\bf HG02107} \\
%\hline
%{\bf } & \multicolumn{2}{c||}{Original} & \multicolumn{2}{c||}{Shuffled} & {\it Diff (\%) } \\
%\cline{2-6}
%{\bf } & {\it All } & {\it Private } & {\it All } & {\it Private } & {\it }\\
%\hline
%\hline
\end{tabular}
\end{center}
{\scriptsize  We list the number of SNV, small indel, and deletion calls in the genomes of HG00096 and HG02107 characterized by different tools using the reads in the original (i.e. as released by 1000 Genomes Project), and shuffled order.
  Calls that are specific to one order of reads are listed as {\it Private}. The difference percentage is calculated as the total number of {\it Private} calls divided by the number of calls in the union set  (i.e. $\frac{|(O\setminus S)~\cup~ (S\setminus O)|}{|O\cup S|}$, $O$: original, $S$: shuffled). $^*$LUMPY crashed in the HG00096 genome analysis, and generated calls only from chromosome 3 in HG02107. $^\ast$Deletions $>$100 bp only.}
%\line(1,0){450}
\label{tab:vars-orig-vs-shuf}
\end{table}


\paragraph{Structural variation.}
Next, we analyzed the deletion calls predicted using DELLY, LUMPY, and Genome STRiP. Unfortunately, LUMPY crashed while running on the HG00096 genome, and we were able to obtain calls only from chromosome 3 using the HG02107 data. Nevertheless, three of four SV detection tools we tested showed 3.5\%- to 25.01\% difference in call sets using the original vs. shuffled order read data sets (Table~\ref{tab:vars-orig-vs-shuf}). Similarly, the discrepancies were mostly found within repeats and duplications, however, only a couple of deletion calls intersected with coding exons (Tables~\ref{supptab:orig-vs-shuf-delly-deletions},~\ref{supptab:orig-vs-shuf-svtoolkit},~\ref{supptab:orig-vs-shuf-lumpy}). 

Using DELLY we predicted $\sim$3\% of deletion, $\sim$4\% of tandem duplication, $\sim$6\% of inversion, and $\sim$3.6\% of translocation calls to be specific to a single alignment, and $>$91\% of these differences intersected with common repeats. Owing to the difficulties in predicting
these types of SVs, more discrepant calls intersected with functionally important regions (i.e. genes and coding exons;  Tables~\ref{supptab:orig-vs-shuf-delly-dups},\ref{supptab:orig-vs-shuf-delly-inv},\ref{supptab:orig-vs-shuf-delly-trans}).

\paragraph{Reusing the same alignments.}
More interestingly, when we ran GATK's HaplotypeCaller on the {\bf same} BAM file twice, we observed discrepant calls similar to using two different BAM files generated from original vs. shuffled read order (Table~\ref{supptab:orig-vs-orig2-hc}).
Other tools produced no discrepancies (Tables~\ref{supptab:orig-vs-orig2-freebayes}-\ref{supptab:orig-vs-orig2-lumpy}).
Detailed analysis of these discordancies revealed that  21,497 of the 21,510 ($>$99.9\%) ``second-run specific'' HaplotypeCaller calls were initially found in the first run, however filtered in the Variant Quality Score Recalibration (VQSR) step. Similarly, 10,631 of the 10,646 ``first-run specific'' HaplotypeCaller calls were eliminated by VQSR in the second run. We then performed a line-by-line analysis in such calls, and found that the {\it VQSLOD} score was calculated differently, although the training data was the same in both runs. 
We speculate that this is due to the random sampling of the training data
to reduce computational burden\footnote{This random subsampling can be seen in the GATK code VariantDataManager.java at %\url{https://github.com/broadgsa/gatk-protected/blob/master/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/variantrecalibration/} (commit ID: {\tt 8ea4dcab8d78e7a7d573fcdc519bd0947a875c06}, line 255)}. 
\url{https://github.com/broadgsa/gatk-protected/} (commit ID: {\tt 8ea4dcab8d78e7a7d573fcdc519bd0947a875c06}, line 255)}. 
We then confirmed our observation by rerunning the VQSR filter on 
one of the VCF files five times. Each iteration of the VQSR filtering generated a different set of VQSLOD values, causing different variants to be filtered.

% main paper tables:

\paragraph{Exome analysis.}
Finally, we tested the effect of discordant call sets generated by GATK even with the same alignment files using 12 whole exome shotgun sequence (WES) data sets from the 1000 Genomes Project (Table~\ref{supptab:data}). We followed the same alignment, post-processing for the WES data sets.
We then generated two call sets each using HaplotypeCaller on the same BAM files, followed with VQSR filtering.
In this experiment, we used the multi-sample calling options. HaplotypeCaller produced discordant calls at 1-to 3\% rate
(Tables~\ref{supptab:orig-vs-orig2-hc},\ref{supptab:orig-vs-orig2-multiple-hc}). 


\vspace*{-0.5cm}
\section{Discussion}

\junk{
The introduction of HTS platforms  quickly revolutionized the way we do biological research\citep{Mardis2008,Metzker2010}. Furthermore, HTS technology  already started to make impact on human health in the form of personalized medicine
through clinical sequencing~\citep{Biesecker2009}, breast cancer subtype detection~\citep{Bosdet2013}, and small molecule drug target site identification~\citep{Rodriguez2014}. However, both sequencing technologies themselves~\citep{Kavak2015},
 and the computational tools are still far from being mature in terms of accuracy~\citep{Alkan2011,Nielsen2011}. The complexity and repetitive nature of human genomes introduce further challenges for reliable characterization of genomic variants~\citep{Treangen2012}.
}

In this paper, we documented the effects of different approaches to handle ambiguities in read mapping due to genomic repeats. We focused on more widely used computational tools for read mapping and variant calling, and observed that random placement of ambiguously mapping reads have an effect on called variants. Although discordancies within repeats are less of a concern due to their relatively negligible 
effects to phenotype, we also discovered hundreds to thousands variants differently detected within coding exons. HaplotypeCaller showed the most discrepancies, where the discordant calls were less pronounced in Freebayes and Platypus results. It was also surprising to see differences in call sets generated using HaplotypeCaller even when the same alignments and variant filtration training data sets were provided. Although we could not fully characterize the reasons
of this observation with GATK, since HaplotypeCaller algorithm is yet unpublished, we observed that the differences were
mainly due to differences in calculation of the {\it VQSLOD} score by the VQSR filter (Results). 

\paragraph{Recommendations.}
 Full reproducibility could only be achieved through using deterministic methods. Therefore, {\bf for full reproducibility}, 
we recommend to opt for a deterministic read mapper such as Bowtie, mrFAST, etc., and a deterministic
variant caller, such as Platypus or Freebayes. Another approach may be more strict filtering of variants that map to repeats and duplications, however this may result in lower detection power in functionally important duplicated genes such as the MHC and KIR loci.
 It may be possible to work around the GATK's VQSLOD calculation problem outlined above by setting the {\tt maxNumTrainingData} parameter and other downsampling parameters to high values, however, we recommend disabling these randomizations by default to be a better practice for uninformed users. In our tests, changing only the {\tt maxNumTrainingData} parameter did not fully resolve the variant filtration problem, which points that there may be other downsampling and/or randomization step within the VQSR filter. We, however, point out that randomized algorithms may achieve better accuracy in practice, without 100\% reproducibility.


\paragraph{Conclusion.}

Mapping short reads to repetitive regions accurately still remains an open problem~\citep{Treangen2012}. Bowtie and mrFAST use 
edit distance and paired-end span distance 
to deterministically assign a single ``best'' map location to ambiguously mapping reads, where BWA-MEM selects a random map location all mapping properties are calculated the same. BWA-MEM assigns a zero mapping quality
to such randomly selected alignments. This approach is still perfectly valid since it informs the downstream analysis tools for problematic alignments, however, as we have documented in this manuscript, 
several variant discovery tools do not fully utilize this information. Complete analysis of the reasons for these discrepancies may warrant code inspection and full disclosure of every algorithmic detail.

The differences in call sets we observed in this study 
have similar sensitivity and specificity when compared to 1000 Genomes data (Supplementary Table~\ref{supptab:1kg-comparison-omni,supptab:1kg-comparison}). In addition a recent study did not find any significant difference between deterministic and non-deterministic mappers in terms of accuracy~\citep{Cornish2015}.
It is still expected to 
have differences between different algorithms and/or parameters, but
obtaining different results should not be due to the order of {\it independently generated} reads in the input file. 
We may simply count these discordancies as false positives and negatives, however, 
we argue that computational predictions should not be effected by luck, and inaccuracies in computational results should be deterministic so they can be better understood and characterized.
We are in exciting times in biological research thanks to the development of HTS technologies. However, under the shining lights of the discoveries we make in this ``big biology'' revolution,  
it can be easy to overlook that the methods matter.
No genomic variant characterization algorithm achieves 100\% accuracy yet, even with  simulation data, but it is only possible to analyze and understand the shortcomings of 
deterministic algorithms, and impossible to fully understand how an algorithm performs if it makes random choices. 
When it comes to use any technology for human health, one would prefer full reproducibility. 

\vspace*{-0.75cm}

\section*{Acknowledgments}

We thank H. Ozercan, A. Gundogdu, A. Senol, and Y. Ozkaya for the initial observation of the effects of reshuffling reads in alignment results using BWA-MEM. We also thank M. Somel, 
O. Gokcumen, E. Cicek, and O. Tastan for
their valuable comments during the preparation of this manuscript.

\paragraph{Funding.}
Funding for this project was provided by a Marie Curie Career Integration Grant (303772) and an 
EMBO Installation Grant (IG-2521) to C.A.

\vspace*{-0.75cm}

\footnotesize
\bibliographystyle{natbib}

\bibliography{calkan.bib}

\clearpage

\input{supptables.tex}

\end{document}
